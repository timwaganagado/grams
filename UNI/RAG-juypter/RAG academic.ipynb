{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f76d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burto/ICTP/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "def extract_texts_from_pdfs(pdf_folder):\n",
    "    all_chunks = []\n",
    "    pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "            # Chunk each paper\n",
    "            chunks = chunk_text(text)\n",
    "            all_chunks.extend(chunks)\n",
    "    return all_chunks\n",
    "\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "#Retrieval and Ollama\n",
    "def search(query, chunks, embeddings, model, top_k=3):\n",
    "    query_emb = model.encode([query])[0]\n",
    "    scores = np.dot(embeddings, query_emb)\n",
    "    top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    return [chunks[i] for i in top_indices]\n",
    "\n",
    "def ask_ollama(context, question, model=\"llama3\"):\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        data = response.json()\n",
    "        return data.get(\"response\", data)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing Ollama response:\", e)\n",
    "        print(\"Raw response text:\", response.text)\n",
    "        return None\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks from all papers: 174\n"
     ]
    }
   ],
   "source": [
    "#Embed all chunks\n",
    "pdf_folder = \"/Users/burto/RAG academic\"  # Change to your folder\n",
    "chunks = extract_texts_from_pdfs(pdf_folder)\n",
    "print(f\"Total chunks from all papers: {len(chunks)}\")\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Answer:\n",
      " A strong paper is characterized by:\n",
      "\n",
      "* A clear and concise thesis statement\n",
      "* Effective organization and structure, including a detailed outline\n",
      "* Well-supported arguments with relevant background information, facts, examples, expert opinions, and other supporting details\n",
      "* Clear and logical connections between ideas\n",
      "* No wordiness or repetition, with sentences that are precise and easy to understand\n",
      "* A smooth flow of ideas from one paragraph to the next\n",
      "* A clear and concise writing style, free from unnecessary jargon or technical terms\n",
      "* Accurate citation and referencing of sources\n",
      "* A well-organized and logical structure, including a brief introduction, background information, literature review, methodology, results, and conclusion.\n"
     ]
    }
   ],
   "source": [
    "#Example query\n",
    "query = \"Summarize what makes a strong paper.\"\n",
    "results = search(query, chunks, embeddings, model)\n",
    "context = \"\\n\".join(results)\n",
    "answer = ask_ollama(context, query)\n",
    "print(\"\\nLLM Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdd780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Feedback:\n",
      " Feedback and Suggestions:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* The essay explores a fascinating topic that has captured human imagination for centuries.\n",
      "* It provides a clear overview of the Martian environment, highlighting its similarities to Earth and potential for supporting life.\n",
      "* The writer effectively incorporates various scientific findings and arguments to support the possibility of life on Mars.\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "1. **Organization:** The essay lacks a clear structure and transitions between paragraphs are abrupt. Consider dividing the text into introduction, body paragraphs, and conclusion.\n",
      "2. **Depth and analysis:** While the essay presents some interesting points, it does not delve deeply enough into the scientific implications of life on Mars or explore potential criticisms of the argument.\n",
      "3. **Clarity and concision:** Some sentences are wordy or unclear. Use simpler language to convey complex ideas, and aim for a consistent tone throughout the essay.\n",
      "\n",
      "**Suggestions:**\n",
      "\n",
      "1. **Introduce the topic more effectively:** Start with a hook that grabs the reader's attention. Instead of beginning with a generic statement about Mars' potential for life, try using an interesting fact or anecdote.\n",
      "2. **Use transitions and connections:** Improve paragraph flow by using transitional phrases (\"However,\" \"In addition,\" etc.) to link ideas between sentences and paragraphs.\n",
      "3. **Develop arguments more thoroughly:** For each point made, provide additional supporting evidence or analysis to strengthen the argument.\n",
      "4. **Cite sources:** Include in-text citations for scientific findings mentioned in the essay (e.g., \"According to NASA's Perseverance rover mission, [cite source]\").\n",
      "5. **Revise the conclusion:** Instead of simply reiterating the main points, use this opportunity to summarize the significance of the topic and its potential implications.\n",
      "\n",
      "**Additional Tips:**\n",
      "\n",
      "1. **Consult with experts:** If possible, consult with astrobiologists or scientists working in related fields to gain a deeper understanding of the topic.\n",
      "2. **Use engaging language:** Use vivid and descriptive language to make the essay more engaging and accessible to a general audience.\n",
      "3. **Edit for grammar and punctuation:** Ensure that the essay is free from errors by thoroughly editing it.\n",
      "\n",
      "By addressing these areas, you can strengthen your argument and create a more compelling, well-structured essay that effectively explores the potential of life on Mars.\n"
     ]
    }
   ],
   "source": [
    "# Example: Use your own PDF as the prompt\n",
    "user_pdf = \"/Users/burto/Downloads/test essay.pdf\"  # Path to your PDF\n",
    "user_text = extract_text_from_pdf(user_pdf)\n",
    "\n",
    "query = \"Give detailed feedback and suggestions for improvement for the following essay.\"\n",
    "results = search(query, chunks, embeddings, model)\n",
    "context = \"\\n\".join(results)\n",
    "\n",
    "# Combine context and your PDF text\n",
    "full_context = f\"{context}\\n\\nEssay:\\n{user_text}\"\n",
    "\n",
    "answer = ask_ollama(full_context, query)\n",
    "print(\"\\nLLM Feedback:\\n\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
